---
image: "https://lh3.googleusercontent.com/eEfDhwb-u99oZnuvwc3STyyWrtN-4LnaqKBXCTP6Zy7yZGEJ-ryNjOOYaWJ3Lc8JmRXVH9DA-EqSb7k61rXtDeG0wB6Tj0ho0mAax8QWUHDkpyUjig=w1200-h630-n-nu"
imageType: source
status: draft
category: Policy
source: Google DeepMind
sourceUrl: https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/
publishedAt: 2025-12-09T11:29:03.000Z
---

---
title: "FACTS Benchmark Suite: Systematically evaluating the factuality of large language models"
category: "Policy"
source: "Google DeepMind"
source_url: "https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/"
published_at: "2025-12-09T11:29:03.000Z"
status: "draft"
---

# FACTS Benchmark Suite: Systematically evaluating the factuality of large language models

<!-- HERO_IMAGE: add an editorial image URL or local path here -->

## WHAT HAPPENED
December 9, 2025 Responsibility & Safety FACTS Benchmark Suite: Systematically evaluating the factuality of large language models Large language models (LLMs) are increasingly becoming a primary source for information delivery across diverse use cases, so it’s important that their responses are factually accurate.In order to continue improving their performance on this industry-wide challenge, we have to better understand the types of use cases where models struggle to provide an accurate response and better measure factuality performance in those areas.Today, we’re teaming up with Kaggle to introduce the FACTS Benchmark Suite. It extends our previous work developing the FACTS Grounding Benchmark, with three additional factuality benchmarks, including:A Parametric Benchmark that measures the model’s ability to access its internal knowledge accurately in factoid question use-cases.A Search Benchmark that tests a model’s ability to use Search as a tool to retrieve information and synthesize it correctly.A Multimodal Benchmark that tests a model’s ability to answer prompts related to input images in a factually correct manner.We are also updating the original FACTS grounding benchmark with Grounding Benchmark - v2, an extended benchmark to test a model’s ability to provide answers grounded in the context of a given prompt.Each benchmark was carefully curated to produce a total of 3,513 examples, which we are making publicly available today. Similar to our previous release, we are following standard industry practice and keeping an evaluation set held-out as a private set.

## WHY IT MATTERS
- _Draft placeholder_
- _Draft placeholder_
- _Draft placeholder_

## WHAT THIS ENABLES
- _Draft placeholder_
- _Draft placeholder_

## SOURCE
https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/
