---
image: "https://lh3.googleusercontent.com/57qjisefBhQ3arKa_KXD07iYqlkUXfuSMxfxl3VyvFZ-IZYyYAaVq5d1IVCGhQGShe1l8u-v_iO7Dnc9lKc8J_y_8gAOF3cm3V2xpnAX_A=w1200-h630-n-nu"
imageType: source
status: draft
category: Industries
source: Google DeepMind
sourceUrl: https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/
publishedAt: 2025-03-12T15:00:00.000Z
---

---
title: "Gemini Robotics brings AI into the physical world"
category: "Industries"
source: "Google DeepMind"
source_url: "https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/"
published_at: "2025-03-12T15:00:00.000Z"
status: "draft"
---

# Gemini Robotics brings AI into the physical world

<!-- HERO_IMAGE: add an editorial image URL or local path here -->

## WHAT HAPPENED
March 12, 2025 Models Introducing Gemini Robotics, our Gemini 2.0-based model designed for roboticsAt Google DeepMind, we've been making progress in how our Gemini models solve complex problems through multimodal reasoning across text, images, audio and video. So far however, those abilities have been largely confined to the digital realm. In order for AI to be useful and helpful to people in the physical realm, they have to demonstrate “embodied” reasoning — the humanlike ability to comprehend and react to the world around us— as well as safely take action to get things done.Today, we are introducing two new AI models, based on Gemini 2.0, which lay the foundation for a new generation of helpful robots.The first is Gemini Robotics, an advanced vision-language-action (VLA) model that was built on Gemini 2.0 with the addition of physical actions as a new output modality for the purpose of directly controlling robots.

## WHY IT MATTERS
- _Draft placeholder_
- _Draft placeholder_
- _Draft placeholder_

## WHAT THIS ENABLES
- _Draft placeholder_
- _Draft placeholder_

## SOURCE
https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/
