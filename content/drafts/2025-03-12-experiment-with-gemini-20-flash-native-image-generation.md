---
image: "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
imageType: source
status: draft
category: Industries
source: Google DeepMind
sourceUrl: https://deepmind.google/blog/experiment-with-gemini-20-flash-native-image-generation/
publishedAt: 2025-03-12T14:58:00.000Z
---

---
title: "Experiment with Gemini 2.0 Flash native image generation"
category: "Industries"
source: "Google DeepMind"
source_url: "https://deepmind.google/blog/experiment-with-gemini-20-flash-native-image-generation/"
published_at: "2025-03-12T14:58:00.000Z"
status: "draft"
---

# Experiment with Gemini 2.0 Flash native image generation

<!-- HERO_IMAGE: add an editorial image URL or local path here -->

## WHAT HAPPENED
MARCH 12, 2025 In December we first introduced native image output in Gemini 2.0 Flash to trusted testers. Today, we're making it available for developer experimentation across all regions currently supported by Google AI Studio. You can test this new capability using an experimental version of Gemini 2.0 Flash (gemini-2.0-flash-exp) in Google AI Studio and via the Gemini API.Gemini 2.0 Flash combines multimodal input, enhanced reasoning, and natural language understanding to create images.Here are some examples of where 2.0 Flashâ€™s multimodal outputs shine:1.

## WHY IT MATTERS
- _Draft placeholder_
- _Draft placeholder_
- _Draft placeholder_

## WHAT THIS ENABLES
- _Draft placeholder_
- _Draft placeholder_

## SOURCE
https://deepmind.google/blog/experiment-with-gemini-20-flash-native-image-generation/
